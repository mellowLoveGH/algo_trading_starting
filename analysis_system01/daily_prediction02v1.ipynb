{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "#!pip install yfinance\n",
    "import yfinance as yf # https://pypi.org/project/yfinance/\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pandas as pd\n",
    "#!pip install sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_realtime_info(stock_code):\n",
    "    URL_link = \"https://www.citifirst.com.hk/en/data/json/json_realtimedata/code/\"+stock_code\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:80.0) Gecko/20100101 Firefox/80.0'}\n",
    "    soup = BeautifulSoup(requests.get(URL_link, headers=headers).content, 'html.parser')\n",
    "\n",
    "    start_index = str(soup).find(\"{\")\n",
    "    end_index = str(soup).find(\"}\")\n",
    "    st = str(soup)[start_index:end_index+1]\n",
    "    json_str = \"\"\n",
    "    for ln in st.split(\",\"):\n",
    "        if \"<\" not in ln:\n",
    "            json_str = json_str + ln + \",\"\n",
    "    dic = json.loads(json_str[:-1])\n",
    "\n",
    "    stock_info = {}\n",
    "    stock_info['Open'] = dic['open']\n",
    "    stock_info['High'] = dic['high']\n",
    "    stock_info['Low'] = dic['low']\n",
    "    stock_info['Close'] = dic['last']\n",
    "    stock_info['previous_Close'] = dic['lastc']\n",
    "    stock_info['turnover'] = dic['turnover']\n",
    "    stock_info['date_time'] = dic['stimeNoformat']\n",
    "    return stock_info\n",
    "\n",
    "# get data by ticker-name, start-time & end-time\n",
    "def get_df_data(ticker_name=\"AAPL\", start_time=\"2022-01-01\", end_time=\"2023-12-31\", real_time=True):\n",
    "    df_data = None\n",
    "    df_data = yf.download(tickers=ticker_name, start=start_time, end=end_time) \n",
    "\n",
    "    if real_time:\n",
    "        stock_info = get_realtime_info(ticker_name)\n",
    "        open_price, high_price, low_price, current_price = stock_info['Open'], stock_info['High'], stock_info['Low'], stock_info['Close']\n",
    "        try:\n",
    "            df_data.at[df_data.index[-1], \"Open\"] = float(open_price)\n",
    "            df_data.at[df_data.index[-1], \"High\"] = float(high_price)\n",
    "            df_data.at[df_data.index[-1], \"Low\"] = float(low_price)\n",
    "            df_data.at[df_data.index[-1], \"Close\"] = float(current_price)\n",
    "        except:\n",
    "            print(stock_info)\n",
    "            df_data.at[df_data.index[-1], \"Open\"] = float(current_price)\n",
    "            df_data.at[df_data.index[-1], \"High\"] = float(current_price)\n",
    "            df_data.at[df_data.index[-1], \"Low\"] = float(current_price)\n",
    "            df_data.at[df_data.index[-1], \"Close\"] = float(current_price)\n",
    "    elif \".HK\" in ticker_name:\n",
    "        print(\"data may late for 15 minutes\")\n",
    "    # basic calculations such as: daily return, the log of Volume, Moving Average\n",
    "    df_data['previous_Close'] = df_data['Close'].shift(1)\n",
    "    df_data['daily_return'] = (df_data['Close']-df_data['previous_Close'])/df_data['previous_Close']\n",
    "    df_data['Volume_log'] = np.log2(df_data['Volume'])\n",
    "    MA1, MA2 = 5, 20\n",
    "    df_data['MA1'] = df_data['Close'].rolling(MA1).mean()\n",
    "    df_data['MA2'] = df_data['Close'].rolling(MA2).mean()\n",
    "    return df_data\n",
    "\n",
    "def get_pair_dates(US_dates, HK_dates):\n",
    "    pair_indexes = []\n",
    "    for hk_d in HK_dates:\n",
    "        idx1 = hk_d\n",
    "        idx2 = None\n",
    "        for us_d in US_dates:\n",
    "            if idx1>=us_d:\n",
    "                idx2 = us_d\n",
    "        if idx2 is not None:\n",
    "            pair_indexes.append( [idx1, idx2] )\n",
    "    return pair_indexes\n",
    "\n",
    "def get_merged_df(HK_stock_df, US_stock_df, target_name=\"Close\", offset_row=20):\n",
    "    #add label for HK stock\n",
    "    HK_stock_df['next_'+target_name] = HK_stock_df[target_name].shift(-1)\n",
    "    # \n",
    "    US_dates = US_stock_df.index\n",
    "    HK_dates = HK_stock_df.index\n",
    "    pair_indexes = get_pair_dates(US_dates, HK_dates)\n",
    "    # \n",
    "    merged_col = [ \"HK_date\", \"HK_Open\", \"HK_High\", \"HK_Low\", \"HK_Close\", \"HK_Volume\", \"HK_MA1\", \"HK_MA2\", \"HK_next_Close\",\n",
    "                    \"US_date\", \"US_Open\", \"US_High\", \"US_Low\", \"US_Close\", \"US_Volume\", \"US_MA1\", \"US_MA2\"\n",
    "                  ]\n",
    "    merged_data = []\n",
    "    for p in pair_indexes[:]:\n",
    "        hk_d, us_d = p[0], p[1]\n",
    "        hk_info, us_info = HK_stock_df.loc[hk_d], US_stock_df.loc[us_d]\n",
    "        hk_use = list(hk_info)[:4] + list(hk_info)[8:-1] # HK_stock_df.columns\n",
    "        us_use = list(us_info)[:4] + list(us_info)[8:] # US_stock_df.columns\n",
    "        label_use = list(hk_info)[-1]\n",
    "        #print( hk_use, us_use, label_use )\n",
    "        it = [hk_d] + hk_use + [label_use] + [us_d] + us_use\n",
    "        merged_data.append( it )\n",
    "    #\n",
    "    merged_df = pd.DataFrame( merged_data, columns=merged_col )\n",
    "    return merged_df[offset_row:].copy()\n",
    "\n",
    "def get_merged_df_update(HK_stock_df, US_stock_df, target_name=\"Close\", offset_row=20):\n",
    "    # next Open is one of the features\n",
    "    HK_stock_df['next_Open'] = HK_stock_df['Open'].shift(-1)\n",
    "\n",
    "    #add label for HK stock\n",
    "    HK_stock_df['next_'+target_name] = HK_stock_df[target_name].shift(-1)    \n",
    "    # \n",
    "    US_dates = US_stock_df.index\n",
    "    HK_dates = HK_stock_df.index\n",
    "    pair_indexes = get_pair_dates(US_dates, HK_dates)\n",
    "    # \n",
    "    merged_col = [ \"HK_date\", \"HK_Open\", \"HK_High\", \"HK_Low\", \"HK_Close\", \"HK_Volume\", \"HK_MA1\", \"HK_MA2\", \"HK_next_Open\", \"HK_next_Close\",\n",
    "                    \"US_date\", \"US_Open\", \"US_High\", \"US_Low\", \"US_Close\", \"US_Volume\", \"US_MA1\", \"US_MA2\"\n",
    "                  ]\n",
    "    merged_data = []\n",
    "    for p in pair_indexes[:]:\n",
    "        hk_d, us_d = p[0], p[1]\n",
    "        hk_info, us_info = HK_stock_df.loc[hk_d], US_stock_df.loc[us_d]\n",
    "        hk_use = list(hk_info)[:4] + list(hk_info)[8:-1] # HK_stock_df.columns, hk_info\n",
    "        us_use = list(us_info)[:4] + list(us_info)[8:] # US_stock_df.columns, us_info\n",
    "        label_use = list(hk_info)[-1]\n",
    "        #print( hk_use, us_use, label_use )\n",
    "        it = [hk_d] + hk_use + [label_use] + [us_d] + us_use\n",
    "        merged_data.append( it )\n",
    "    #\n",
    "    merged_df = pd.DataFrame( merged_data, columns=merged_col )\n",
    "    return merged_df[offset_row:].copy()\n",
    "\n",
    "\n",
    "# LR model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def train_model(train_X, train_y, printing=True):\n",
    "    model = LinearRegression().fit(train_X, train_y)\n",
    "\n",
    "    r_sq = model.score(train_X, train_y)\n",
    "    if printing:\n",
    "        print(f\"coefficient of determination: {r_sq}\")\n",
    "        print(f\"intercept: {model.intercept_}\\tslope: {model.coef_}\")\n",
    "    return model\n",
    "\n",
    "def error_analyze(train_y, y_pred):\n",
    "    df = pd.DataFrame(columns = ['y_real', 'y_pred'])\n",
    "    df['y_real'] = train_y\n",
    "    df['y_pred'] = y_pred\n",
    "    df['dif'] = (df['y_real'] - df['y_pred'])/df['y_real'] * 100\n",
    "    df['dif'] = df['dif'].abs()\n",
    "    return df\n",
    "\n",
    "def basic_info(df, col='dif'):\n",
    "    print(\"max:\\t\", df[col].max())\n",
    "    print(\"min:\\t\", df[col].min())\n",
    "    print(\"median:\\t\", df[col].median())\n",
    "    print(\"mean:\\t\", df[col].mean())\n",
    "    print(\"std:\\t\", df[col].std())\n",
    "    print(\"10%:\\t\", df[col].quantile(0.10))\n",
    "    print(\"25%:\\t\", df[col].quantile(0.25))\n",
    "    print(\"50%:\\t\", df[col].quantile(0.50))\n",
    "    print(\"75%:\\t\", df[col].quantile(0.75))\n",
    "    print(\"90%:\\t\", df[col].quantile(0.90))\n",
    "    return\n",
    "\n",
    "def predict_current_next_days01(merged_df, train_rows=120, test_row1=-2, test_row2=-1):\n",
    "    row_data1 = merged_df.iloc[test_row1]\n",
    "    test_data1, label1 = [list(row_data1)[1:8]+list(row_data1)[10:]], list(row_data1)[8]\n",
    "    d1 = list(row_data1)[0]\n",
    "    row_data2 = merged_df.iloc[test_row2]\n",
    "    test_data2, label2 = [list(row_data2)[1:8]+list(row_data2)[10:]], list(row_data2)[8]\n",
    "    d2 = list(row_data2)[0]\n",
    "    #\n",
    "    train_df = merged_df[-train_rows-2:-2].copy()\n",
    "    X_data, y_data = [], []\n",
    "    dates01, dates02 = [], []\n",
    "    i = 0\n",
    "    while i<len(train_df):\n",
    "        row_info = train_df.iloc[i]\n",
    "        sub_x = list(row_info)[1:8]+list(row_info)[10:]\n",
    "        sub_y = list(row_info)[8]\n",
    "        #print(row_info)\n",
    "        X_data.append( sub_x )\n",
    "        y_data.append( sub_y )\n",
    "        #\n",
    "        dates01.append( row_info[0] )\n",
    "        dates02.append( row_info[9] )\n",
    "        i += 1\n",
    "    #\n",
    "    model = train_model(X_data, y_data)\n",
    "    y_pred = model.predict(X_data) # error analysis\n",
    "    error_df = error_analyze(y_data, y_pred)\n",
    "    error_df['HK_date'] = dates01\n",
    "    error_df['US_date'] = dates02\n",
    "\n",
    "    #\n",
    "    test_y_pred1 = model.predict(test_data1)[0]\n",
    "    test_y_real1 = label1\n",
    "    test_y_pred2 = model.predict(test_data2)[0]\n",
    "    test_y_real2 = label2\n",
    "    return error_df, (d1, test_y_pred1, test_y_real1), (d2, test_y_pred2, test_y_real2)\n",
    "\n",
    "def predict_current_next_days02(merged_df, train_rows=120, test_row1=-2, test_row2=-1):\n",
    "    row_data1 = merged_df.iloc[test_row1]\n",
    "    test_data1, label1 = [list(row_data1)[1:9]+list(row_data1)[11:]], list(row_data1)[9]\n",
    "    d1 = list(row_data1)[0] # (d1, test_data1, label1)\n",
    "    row_data2 = merged_df.iloc[test_row2]\n",
    "    test_data2, label2 = [list(row_data2)[1:9]+list(row_data2)[11:]], list(row_data2)[9]\n",
    "    d2 = list(row_data2)[0] # (d2, test_data2, label2)\n",
    "    # \n",
    "    train_df = merged_df[-train_rows-2:-2].copy()\n",
    "    X_data, y_data = [], []\n",
    "    dates01, dates02 = [], []\n",
    "    i = 0\n",
    "    while i<len(train_df):\n",
    "        row_info = train_df.iloc[i]\n",
    "        sub_x = list(row_info)[1:9]+list(row_info)[11:]\n",
    "        sub_y = list(row_info)[9]\n",
    "        #print(row_info)\n",
    "        X_data.append( sub_x )\n",
    "        y_data.append( sub_y )\n",
    "        #\n",
    "        dates01.append( row_info[0] )\n",
    "        dates02.append( row_info[10] )\n",
    "        i += 1\n",
    "    #\n",
    "    model = train_model(X_data, y_data)\n",
    "    y_pred = model.predict(X_data) # error analysis\n",
    "    error_df = error_analyze(y_data, y_pred)\n",
    "    error_df['HK_date'] = dates01\n",
    "    error_df['US_date'] = dates02\n",
    "\n",
    "    #\n",
    "    test_y_pred1 = model.predict(test_data1)[0]\n",
    "    test_y_real1 = label1\n",
    "    #test_y_pred2 = model.predict(test_data2)[0]\n",
    "    #test_y_real2 = label2\n",
    "    return error_df, (d1, test_y_pred1, test_y_real1), (d2, test_data2, label2) #(d2, test_y_pred2, test_y_real2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "coefficient of determination: 0.9728742650715233\n",
      "intercept: -3.458779987225256\tslope: [ 0.01324108  0.14816035 -0.13530156 -0.16530105  0.1159919   0.12011254\n",
      "  0.23849598 -0.36136073  0.48692786  0.67832353  0.29561466  0.00455057\n",
      " -0.10962024 -0.22110116]\n"
     ]
    }
   ],
   "source": [
    "stocks_info = [\n",
    "    ('BABA', '9988.HK', 1),\n",
    "    ('BIDU', '9888.HK', 1),\n",
    "    ('JD', '9618.HK', 0.5 * 7.8),\n",
    "    ('MPNGY', '3690.HK', 0.5 * 7.8),\n",
    "    ('NTES', '9999.HK', 0.2 * 7.8),\n",
    "\t('LI', '2015.HK', 0.5 * 7.8),\n",
    "\t('XPEV', '9868.HK', 0.5*7.8),\t\n",
    "\t('BILI', '9626.HK', 1 * 7.8),\n",
    "\t('TCOM', '9961.HK', 1 * 7.8),\n",
    "\t('YUMC', '9987.HK', 1*7.8),\n",
    "\t('EDU', '9901.HK', 0.1*7.8), \n",
    "    ('NIO', '9866.HK', 1 * 7.8),\n",
    "\t('ZTO', '2057.HK', 1*7.8),\n",
    "    ('BEKE', '2423.HK', 0.5*7.8),\n",
    "    ('ZH', '2390.HK', 3 * 7.8), \n",
    "    ('WB', '9898.HK', 1*7.8),\n",
    "    ('MNSO', '9896.HK', 0.5*7.8),\n",
    "    ('ZLAB', '9688.HK', 0.5*7.8),\n",
    "    ('TME', '1698.HK', 1*7.8),\n",
    "]\n",
    "\n",
    "st, et = \"2021-01-01\", \"2023-08-31\"\n",
    "US_stock_code, HK_stock_code, _ = stocks_info[0]\n",
    "US_stock_df = get_df_data(US_stock_code, st, et, False)\n",
    "HK_stock_df = get_df_data(HK_stock_code, st, et, True)\n",
    "\n",
    "mode = 1\n",
    "if mode == 1:\n",
    "    target_name = \"Close\"\n",
    "    merged_df = get_merged_df(HK_stock_df, US_stock_df, target_name, 20)\n",
    "    error_df, pred_it1, it2 = predict_current_next_days01(merged_df, 200, -2, -1)\n",
    "elif mode == 2:\n",
    "    target_name = \"Close\"\n",
    "    merged_df = get_merged_df_update(HK_stock_df, US_stock_df, target_name, 20)\n",
    "    error_df, pred_it1, it2 = predict_current_next_days02(merged_df, 200, -2, -1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Timestamp('2023-08-10 00:00:00'), 97.94499491833758, 96.2),\n",
       " (Timestamp('2023-08-11 00:00:00'), 97.79693654984897, nan))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_it1, it2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Timestamp('2023-08-10 00:00:00'), 97.94499491833758, 96.2),\n",
       " (Timestamp('2023-08-11 00:00:00'), 97.79693654984897, nan))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_it1, it2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
